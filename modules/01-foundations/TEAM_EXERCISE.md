# Team Exercise: Prompt Battle & AI Trust Calibration

**Time:** 5-10 minutes
**Format:** Pairs or small groups (2-3 people)
**Goal:** Share learnings and calibrate your "AI trust level"

---

## Part 1: Prompt Comparison (3-4 min)

### Instructions:

**In pairs/groups:**

1. **Share your prompts** - Each person shares ONE prompt they used during Module 1
   - What did you ask AI?
   - What response did you get?
   - Did it work or mislead you?

2. **Compare approaches** - Discuss:
   - What made a good prompt effective?
   - What made a bad prompt fail?
   - Did anyone get completely different results from similar prompts?

3. **Find the winner** - Which prompt in your group was:
   - **Most effective?** (Got the best result first try)
   - **Most misleading?** (AI confidently wrong)
   - **Most surprising?** (Unexpected but good result)

---

## Part 2: AI Trust Calibration (2-3 min)

### Quick Poll - Where Are You Now?

**Rate yourself on these statements (1-5 scale):**

1. **"I trust AI-generated code without reviewing it"**
   - 1 = Never trust blindly
   - 5 = Ship it if it compiles

2. **"AI understands accessibility requirements"**
   - 1 = AI always misses a11y
   - 5 = AI nails accessibility

3. **"If AI code works in my tests, it's production-ready"**
   - 1 = Working â‰  correct
   - 5 = Tests passing = good to go

4. **"I can explain all the AI-generated code I commit"**
   - 1 = Always understand every line
   - 5 = Trust AI knows best

### Group Discussion:

**Share with your group:**
- Where did your scores differ most?
- Did Module 1 change your trust level?
- What surprised you about AI's mistakes?

---

## Part 3: One Thing You'll Change (2-3 min)

### Quick Round-Robin:

Each person shares **ONE specific thing** they'll do differently after Module 1:

**Examples:**
- "I'll always test accessibility manually, not trust AI"
- "I'll ask for 3 different approaches before choosing"
- "I'll verify AI's assumptions about my data structure"
- "I'll read every line of AI code before committing"
- "I'll test error cases, not just happy paths"

---

## Facilitator Notes:

### Setup:
- Break into pairs/groups of 2-3
- Set a timer for each part
- Encourage quick sharing, not deep dives

### What to Listen For:

**Good signs participants are learning:**
- âœ… "AI gave me working code but it was inaccessible"
- âœ… "I had to verify AI's claims"
- âœ… "Testing caught what AI missed"
- âœ… "I understand why my prompt failed"

**Red flags to address:**
- ğŸš© "AI always gets it right"
- ğŸš© "I don't need to understand the code"
- ğŸš© "Accessibility is AI's problem"
- ğŸš© "If it compiles, ship it"

### Key Takeaways to Reinforce:

1. **Context matters** - AI needs the right information
2. **AI doesn't know accessibility** - You must verify
3. **Working â‰  Correct** - Test beyond happy paths
4. **Understand what you commit** - No blind trust
5. **Different prompts = different results** - Iteration is normal

---

## Quick Variant: Speed Round (5 min total)

If short on time, just do:

1. **30 seconds per person:** Share your best or worst prompt
2. **2 minutes:** Quick discussion of what made prompts effective
3. **2 minutes:** Everyone shares ONE thing they learned

---

## Follow-Up (Optional):

**Create a "Lessons Learned" board:**
- Post-it notes or digital board
- Everyone adds one AI "gotcha" they discovered
- Reference this in later modules

**Categories:**
- ğŸ› Bugs AI Created
- â™¿ Accessibility AI Missed
- ğŸ’¡ Surprising AI Wins
- ğŸ¤” Prompt Techniques That Worked

---

## Expected Outcomes:

After this exercise, participants should:
- âœ… Realize others had similar challenges
- âœ… Learn from each other's prompting strategies
- âœ… Calibrate their trust in AI appropriately
- âœ… Have one concrete behavior change
- âœ… Feel more confident for Module 2

---

**Remember:** This is about sharing and learning, not judging. Everyone's at different levels - the goal is to learn together!
